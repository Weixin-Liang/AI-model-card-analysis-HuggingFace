{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hugging Face Hub API Examples\n",
    "For more information, see the [Hugging Face Hub API documentation](https://huggingface.co/docs/hub/api)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Information of Models and Their MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\envs\\chatgpt\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\envs\\chatgpt\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:229: FutureWarning: 'list_models' currently returns a list of objects but is planned to be a generator starting from version 0.14 in order to implement pagination. Please avoid to use `list_models(...).__len__` or explicitly convert the output to a list first with `list(iter(list_models)(...))`.\n",
      "  warnings.warn(self._deprecation_msg.format(attr_name=attr_name), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# list all models\n",
    "models = huggingface_hub.list_models(full=True,cardData=True, sort='downloads', direction=-1)\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelInfo: { \n",
       "  {'_id': '621ffdc136468d709f17cdb3',\n",
       "   'author': 'jonatasgrosman',\n",
       "   'cardData': {'datasets': ['common_voice', 'mozilla-foundation/common_voice_6_0'],\n",
       "                'language': 'en',\n",
       "                'license': 'apache-2.0',\n",
       "                'metrics': ['wer', 'cer'],\n",
       "                'model-index': [{'name': 'XLSR Wav2Vec2 English by Jonatas Grosman',\n",
       "                                 'results': [{'dataset': {'args': 'en',\n",
       "                                                          'name': 'Common Voice en',\n",
       "                                                          'type': 'common_voice'},\n",
       "                                              'metrics': [{'name': 'Test WER',\n",
       "                                                           'type': 'wer',\n",
       "                                                           'value': 19.06,\n",
       "                                                           'verified': False},\n",
       "                                                          {'name': 'Test CER',\n",
       "                                                           'type': 'cer',\n",
       "                                                           'value': 7.69,\n",
       "                                                           'verified': False},\n",
       "                                                          {'name': 'Test WER (+LM)',\n",
       "                                                           'type': 'wer',\n",
       "                                                           'value': 14.81,\n",
       "                                                           'verified': False},\n",
       "                                                          {'name': 'Test CER (+LM)',\n",
       "                                                           'type': 'cer',\n",
       "                                                           'value': 6.84,\n",
       "                                                           'verified': False}],\n",
       "                                              'task': {'name': 'Automatic Speech Recognition',\n",
       "                                                       'type': 'automatic-speech-recognition'}},\n",
       "                                             {'dataset': {'args': 'en',\n",
       "                                                          'name': 'Robust Speech Event - Dev Data',\n",
       "                                                          'type': 'speech-recognition-community-v2/dev_data'},\n",
       "                                              'metrics': [{'name': 'Dev WER',\n",
       "                                                           'type': 'wer',\n",
       "                                                           'value': 27.72,\n",
       "                                                           'verified': False},\n",
       "                                                          {'name': 'Dev CER',\n",
       "                                                           'type': 'cer',\n",
       "                                                           'value': 11.65,\n",
       "                                                           'verified': False},\n",
       "                                                          {'name': 'Dev WER (+LM)',\n",
       "                                                           'type': 'wer',\n",
       "                                                           'value': 20.85,\n",
       "                                                           'verified': False},\n",
       "                                                          {'name': 'Dev CER (+LM)',\n",
       "                                                           'type': 'cer',\n",
       "                                                           'value': 11.01,\n",
       "                                                           'verified': False}],\n",
       "                                              'task': {'name': 'Automatic Speech Recognition',\n",
       "                                                       'type': 'automatic-speech-recognition'}}]}],\n",
       "                'tags': ['audio', 'automatic-speech-recognition', 'en', 'hf-asr-leaderboard',\n",
       "                         'mozilla-foundation/common_voice_6_0', 'robust-speech-event', 'speech',\n",
       "                         'xlsr-fine-tuning-week']},\n",
       "   'config': None,\n",
       "   'downloads': 60392722,\n",
       "   'id': 'jonatasgrosman/wav2vec2-large-xlsr-53-english',\n",
       "   'lastModified': '2023-03-25T10:56:55.000Z',\n",
       "   'library_name': 'transformers',\n",
       "   'likes': 150,\n",
       "   'modelId': 'jonatasgrosman/wav2vec2-large-xlsr-53-english',\n",
       "   'pipeline_tag': 'automatic-speech-recognition',\n",
       "   'private': False,\n",
       "   'securityStatus': None,\n",
       "   'sha': '569a6236e92bd5f7652a0420bfe9bb94c5664080',\n",
       "   'siblings': [RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': '.gitattributes', 'size': None},\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'README.md', 'size': None},\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'alphabet.json', 'size': None},\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'config.json', 'size': None},\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'eval.py', 'size': None},\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'flax_model.msgpack', 'size': None},\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'full_eval.sh', 'size': None},\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'language_model/attrs.json', 'size': None},\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'language_model/lm.binary', 'size': None},\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'language_model/unigrams.txt', 'size': None},\n",
       "                RepoFile: { \n",
       "    {'blob_id': None,\n",
       "     'lfs': None,\n",
       "     'rfilename': 'log_mozilla-foundation_common_voice_6_0_en_test_predictions.txt',\n",
       "     'size': None}\n",
       "  },\n",
       "                RepoFile: { \n",
       "    {'blob_id': None,\n",
       "     'lfs': None,\n",
       "     'rfilename': 'log_mozilla-foundation_common_voice_6_0_en_test_predictions_greedy.txt',\n",
       "     'size': None}\n",
       "  },\n",
       "                RepoFile: { \n",
       "    {'blob_id': None,\n",
       "     'lfs': None,\n",
       "     'rfilename': 'log_mozilla-foundation_common_voice_6_0_en_test_targets.txt',\n",
       "     'size': None}\n",
       "  },\n",
       "                RepoFile: { \n",
       "    {'blob_id': None,\n",
       "     'lfs': None,\n",
       "     'rfilename': 'log_speech-recognition-community-v2_dev_data_en_validation_predictions.txt',\n",
       "     'size': None}\n",
       "  },\n",
       "                RepoFile: { \n",
       "    {'blob_id': None,\n",
       "     'lfs': None,\n",
       "     'rfilename': 'log_speech-recognition-community-v2_dev_data_en_validation_predictions_greedy.txt',\n",
       "     'size': None}\n",
       "  },\n",
       "                RepoFile: { \n",
       "    {'blob_id': None,\n",
       "     'lfs': None,\n",
       "     'rfilename': 'log_speech-recognition-community-v2_dev_data_en_validation_targets.txt',\n",
       "     'size': None}\n",
       "  },\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'model.safetensors', 'size': None},\n",
       "                RepoFile: { \n",
       "    {'blob_id': None,\n",
       "     'lfs': None,\n",
       "     'rfilename': 'mozilla-foundation_common_voice_6_0_en_test_eval_results.txt',\n",
       "     'size': None}\n",
       "  },\n",
       "                RepoFile: { \n",
       "    {'blob_id': None,\n",
       "     'lfs': None,\n",
       "     'rfilename': 'mozilla-foundation_common_voice_6_0_en_test_eval_results_greedy.txt',\n",
       "     'size': None}\n",
       "  },\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'preprocessor_config.json', 'size': None},\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'pytorch_model.bin', 'size': None},\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'special_tokens_map.json', 'size': None},\n",
       "                RepoFile: { \n",
       "    {'blob_id': None,\n",
       "     'lfs': None,\n",
       "     'rfilename': 'speech-recognition-community-v2_dev_data_en_validation_eval_results.txt',\n",
       "     'size': None}\n",
       "  },\n",
       "                RepoFile: { \n",
       "    {'blob_id': None,\n",
       "     'lfs': None,\n",
       "     'rfilename': 'speech-recognition-community-v2_dev_data_en_validation_eval_results_greedy.txt',\n",
       "     'size': None}\n",
       "  },\n",
       "                RepoFile: {'blob_id': None, 'lfs': None, 'rfilename': 'vocab.json', 'size': None}],\n",
       "   'tags': ['pytorch', 'jax', 'safetensors', 'wav2vec2', 'automatic-speech-recognition', 'en', 'dataset:common_voice',\n",
       "            'dataset:mozilla-foundation/common_voice_6_0', 'transformers', 'audio', 'hf-asr-leaderboard',\n",
       "            'mozilla-foundation/common_voice_6_0', 'robust-speech-event', 'speech', 'xlsr-fine-tuning-week',\n",
       "            'license:apache-2.0', 'model-index', 'has_space']}\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_example = models[0]\n",
    "model_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60392722"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the metadata of a dataset (e.g., downloads)\n",
    "model_example.downloads"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import ModelCard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<huggingface_hub.repocard.ModelCard at 0x291251620b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_card = ModelCard.load(model_example.modelId)\n",
    "model_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "language: en\n",
      "license: apache-2.0\n",
      "tags:\n",
      "- audio\n",
      "- automatic-speech-recognition\n",
      "- en\n",
      "- hf-asr-leaderboard\n",
      "- mozilla-foundation/common_voice_6_0\n",
      "- robust-speech-event\n",
      "- speech\n",
      "- xlsr-fine-tuning-week\n",
      "datasets:\n",
      "- common_voice\n",
      "- mozilla-foundation/common_voice_6_0\n",
      "metrics:\n",
      "- wer\n",
      "- cer\n",
      "model-index:\n",
      "- name: XLSR Wav2Vec2 English by Jonatas Grosman\n",
      "  results:\n",
      "  - task:\n",
      "      type: automatic-speech-recognition\n",
      "      name: Automatic Speech Recognition\n",
      "    dataset:\n",
      "      name: Common Voice en\n",
      "      type: common_voice\n",
      "      args: en\n",
      "    metrics:\n",
      "    - type: wer\n",
      "      value: 19.06\n",
      "      name: Test WER\n",
      "    - type: cer\n",
      "      value: 7.69\n",
      "      name: Test CER\n",
      "    - type: wer\n",
      "      value: 14.81\n",
      "      name: Test WER (+LM)\n",
      "    - type: cer\n",
      "      value: 6.84\n",
      "      name: Test CER (+LM)\n",
      "  - task:\n",
      "      type: automatic-speech-recognition\n",
      "      name: Automatic Speech Recognition\n",
      "    dataset:\n",
      "      name: Robust Speech Event - Dev Data\n",
      "      type: speech-recognition-community-v2/dev_data\n",
      "      args: en\n",
      "    metrics:\n",
      "    - type: wer\n",
      "      value: 27.72\n",
      "      name: Dev WER\n",
      "    - type: cer\n",
      "      value: 11.65\n",
      "      name: Dev CER\n",
      "    - type: wer\n",
      "      value: 20.85\n",
      "      name: Dev WER (+LM)\n",
      "    - type: cer\n",
      "      value: 11.01\n",
      "      name: Dev CER (+LM)\n",
      "---\n",
      "\n",
      "# Fine-tuned XLSR-53 large model for speech recognition in English\n",
      "\n",
      "Fine-tuned [facebook/wav2vec2-large-xlsr-53](https://huggingface.co/facebook/wav2vec2-large-xlsr-53) on English using the train and validation splits of [Common Voice 6.1](https://huggingface.co/datasets/common_voice).\n",
      "When using this model, make sure that your speech input is sampled at 16kHz.\n",
      "\n",
      "This model has been fine-tuned thanks to the GPU credits generously given by the [OVHcloud](https://www.ovhcloud.com/en/public-cloud/ai-training/) :)\n",
      "\n",
      "The script used for training can be found here: https://github.com/jonatasgrosman/wav2vec2-sprint\n",
      "\n",
      "## Usage\n",
      "\n",
      "The model can be used directly (without a language model) as follows...\n",
      "\n",
      "Using the [HuggingSound](https://github.com/jonatasgrosman/huggingsound) library:\n",
      "\n",
      "```python\n",
      "from huggingsound import SpeechRecognitionModel\n",
      "\n",
      "model = SpeechRecognitionModel(\"jonatasgrosman/wav2vec2-large-xlsr-53-english\")\n",
      "audio_paths = [\"/path/to/file.mp3\", \"/path/to/another_file.wav\"]\n",
      "\n",
      "transcriptions = model.transcribe(audio_paths)\n",
      "```\n",
      "\n",
      "Writing your own inference script:\n",
      "\n",
      "```python\n",
      "import torch\n",
      "import librosa\n",
      "from datasets import load_dataset\n",
      "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
      "\n",
      "LANG_ID = \"en\"\n",
      "MODEL_ID = \"jonatasgrosman/wav2vec2-large-xlsr-53-english\"\n",
      "SAMPLES = 10\n",
      "\n",
      "test_dataset = load_dataset(\"common_voice\", LANG_ID, split=f\"test[:{SAMPLES}]\")\n",
      "\n",
      "processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
      "model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)\n",
      "\n",
      "# Preprocessing the datasets.\n",
      "# We need to read the audio files as arrays\n",
      "def speech_file_to_array_fn(batch):\n",
      "    speech_array, sampling_rate = librosa.load(batch[\"path\"], sr=16_000)\n",
      "    batch[\"speech\"] = speech_array\n",
      "    batch[\"sentence\"] = batch[\"sentence\"].upper()\n",
      "    return batch\n",
      "\n",
      "test_dataset = test_dataset.map(speech_file_to_array_fn)\n",
      "inputs = processor(test_dataset[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
      "\n",
      "with torch.no_grad():\n",
      "    logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
      "\n",
      "predicted_ids = torch.argmax(logits, dim=-1)\n",
      "predicted_sentences = processor.batch_decode(predicted_ids)\n",
      "\n",
      "for i, predicted_sentence in enumerate(predicted_sentences):\n",
      "    print(\"-\" * 100)\n",
      "    print(\"Reference:\", test_dataset[i][\"sentence\"])\n",
      "    print(\"Prediction:\", predicted_sentence)\n",
      "```\n",
      "\n",
      "| Reference  | Prediction |\n",
      "| ------------- | ------------- |\n",
      "| \"SHE'LL BE ALL RIGHT.\" | SHE'LL BE ALL RIGHT |\n",
      "| SIX | SIX |\n",
      "| \"ALL'S WELL THAT ENDS WELL.\" | ALL AS WELL THAT ENDS WELL |\n",
      "| DO YOU MEAN IT? | DO YOU MEAN IT |\n",
      "| THE NEW PATCH IS LESS INVASIVE THAN THE OLD ONE, BUT STILL CAUSES REGRESSIONS. | THE NEW PATCH IS LESS INVASIVE THAN THE OLD ONE BUT STILL CAUSES REGRESSION |\n",
      "| HOW IS MOZILLA GOING TO HANDLE AMBIGUITIES LIKE QUEUE AND CUE? | HOW IS MOSLILLAR GOING TO HANDLE ANDBEWOOTH HIS LIKE Q AND Q |\n",
      "| \"I GUESS YOU MUST THINK I'M KINDA BATTY.\" | RUSTIAN WASTIN PAN ONTE BATTLY |\n",
      "| NO ONE NEAR THE REMOTE MACHINE YOU COULD RING? | NO ONE NEAR THE REMOTE MACHINE YOU COULD RING |\n",
      "| SAUCE FOR THE GOOSE IS SAUCE FOR THE GANDER. | SAUCE FOR THE GUICE IS SAUCE FOR THE GONDER |\n",
      "| GROVES STARTED WRITING SONGS WHEN SHE WAS FOUR YEARS OLD. | GRAFS STARTED WRITING SONGS WHEN SHE WAS FOUR YEARS OLD |\n",
      "\n",
      "## Evaluation\n",
      "\n",
      "1. To evaluate on `mozilla-foundation/common_voice_6_0` with split `test`\n",
      "\n",
      "```bash\n",
      "python eval.py --model_id jonatasgrosman/wav2vec2-large-xlsr-53-english --dataset mozilla-foundation/common_voice_6_0 --config en --split test\n",
      "```\n",
      "\n",
      "2. To evaluate on `speech-recognition-community-v2/dev_data`\n",
      "\n",
      "```bash\n",
      "python eval.py --model_id jonatasgrosman/wav2vec2-large-xlsr-53-english --dataset speech-recognition-community-v2/dev_data --config en --split validation --chunk_length_s 5.0 --stride_length_s 1.0\n",
      "```\n",
      "\n",
      "## Citation\n",
      "If you want to cite this model you can use this:\n",
      "\n",
      "```bibtex\n",
      "@misc{grosman2021xlsr53-large-english,\n",
      "  title={Fine-tuned {XLSR}-53 large model for speech recognition in {E}nglish},\n",
      "  author={Grosman, Jonatas},\n",
      "  howpublished={\\url{https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-english}},\n",
      "  year={2021}\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(model_card.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Access to the Models Repo and Downloads It"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid conflicts with the '/' character, which is commonly used as a path separator, we replace it with '_' when creating the filename for a model card. This allows us to split the author name and dataset name for better organization. For example, the repository for `jonatasgrosman/wav2vec2-large-xlsr-53-english` will be saved as `jonatasgrosman'wav2vec2-large-xlsr-53-english`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "username = '' # specify your huggingface username\n",
    "password = '' # specify your huggingface password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jonatasgrosman/wav2vec2-large-xlsr-53-english'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = model_example.modelId\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = model_name.replace('/', \"'\")\n",
    "path = f'../models_repo/{name}' # specify your storage path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "git.Repo.clone_from(url=f'https://{username}:{password}@huggingface.co/{model_name}', to_path=f'{path}{name}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
